{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNS59mUhRWeFpAmGyjGnop1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "word2vec= need \"Gensim\" library, it forms vectors of each word using a shallow neural network -we get vector at word level , includes neigbour as suggested in window of n number of left and right negbhour words (used when we need to compare word to word ) [q&A, similarity, next word prediction]\n",
        "\n",
        "tfidf= will create embedding at document level only, similar to bag of word ( term frequency) BUT will give you highest score to most unique words, its improvement over bag of words [topic modelling(ldm), classifiaction, doc similarity]\n",
        "\n",
        "bag of words= count vectorizer = will create embedding at document level only, each document can include any number of words passed in ONE cell/row [used in topic modelling(ldm), classifiaction, doc similarity]\n",
        "\n",
        "ngram= how many words to be taken togeather for analysis ( unigram= 1 word, bigram , 2 , trigram= 3 words etc.breaks the sentence in \"n\"gram for analysis)\n",
        "\n",
        "skip gram= continuous bag of words are TWO methods of generating embeddings for word to vec models"
      ],
      "metadata": {
        "id": "KzNvB8jbzwNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "R4nPRoP9tkbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=pd.read_excel(\"/content/sentiment-nlp1.xlsx\")"
      ],
      "metadata": {
        "id": "7lNPgWK0tXtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoBvp1RoqgfD"
      },
      "outputs": [],
      "source": [
        "#preprocessing\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "\n",
        "def preprocess(input_sentence):\n",
        "  input_sentence=input_sentence.lower()\n",
        "  #input_tokens=input_sentence.split()\n",
        "  input_sentence=remove_punctuation(input_sentence)\n",
        "  return input_sentence\n",
        "\n",
        "def remove_punctuation(input_string):\n",
        "  # Make a regular expression that matches all punctuation\n",
        "  regex = re.compile('[%s]' % re.escape(string.punctuation + \"—•\"))\n",
        "  # Use the regex\n",
        "  return regex.sub(' ', input_string)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data[\"sentence\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQUawxD62PwM",
        "outputId": "b3cd9293-1700-40c1-c37a-0e7062706862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[\"sentence\"]=train_data[\"sentence\"].apply(preprocess)"
      ],
      "metadata": {
        "id": "cWzRtx2Zt6Y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xVYXm7d92PR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing preporocessing , Note: need to convert type from list to series??"
      ],
      "metadata": {
        "id": "RsHX-BG_1UVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data1= [\"In Karma Yoga, the three gunas (qualities or attributes) from Hindu  philosophy play a significant role These gunas are fundamental forces that influence human behavior,thoughts,and actions. The three gunas are:Sattva ('purity, harmony'): Sattva represents the quality of purity,harmony, and balance.\"]\n"
      ],
      "metadata": {
        "id": "ll8B4NoI0hqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data2= [\"three gunas are always present in all beings and objects surrounding us but vary in their relative amounts. We humans have the unique ability to consciously alter the levels of the gunas in our bodies and minds. The gunas cannot be separated or removed in oneself but can be consciously acted upon to encourage their increase or decrease. A guna can be increased or decreased through the interaction and influence of external objects, lifestyle practices and thoughts.\"]"
      ],
      "metadata": {
        "id": "WdwtHnAEH0gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#chunking and tokenizing"
      ],
      "metadata": {
        "id": "eiZFTX0wLXj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer\n",
        "# import the existing word and sentence tokenizing\n",
        "# libraries\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZey7or8LkfZ",
        "outputId": "562407d5-94f9-4d75-d3d0-cb253b6afb53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chunking and tokenizing\n",
        "print(sent_tokenize(test_data1_processed[0])) #to be used when tokenizing sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSK0AjI4LbrX",
        "outputId": "40a15740-5601-42a7-aa5d-765b88f13cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in karma yoga  the three gunas  qualities or attributes  from hindu  philosophy play a significant role these gunas are fundamental forces that influence human behavior thoughts and actions  the three gunas are sattva   purity  harmony    sattva represents the quality of purity harmony  and balance']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "coverting from data type list to STRING"
      ],
      "metadata": {
        "id": "vjpk_hlcOhTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data1= pd.Series(test_data1)\n",
        "test_data2= pd.Series(test_data2)\n",
        "type(test_data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM0_Pg-hNZ__",
        "outputId": "f712c0d2-95e1-4d17-9d64-3edc660e197a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentence_list_doc1= sent_tokenize(test_data1[0])\n",
        "sentence_list_doc2= sent_tokenize(test_data2[0])\n",
        "sentence_list_doc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_4tU8TJOzVk",
        "outputId": "75587de0-e083-479e-f7fc-a3ef35f98979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In Karma Yoga, the three gunas (qualities or attributes) from Hindu  philosophy play a significant role These gunas are fundamental forces that influence human behavior,thoughts,and actions.',\n",
              " \"The three gunas are:Sattva ('purity, harmony'): Sattva represents the quality of purity,harmony, and balance.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TFIDF word embedding"
      ],
      "metadata": {
        "id": "KaJo1t7LQxa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TFIDF word embeeding = vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = sentence_list_doc1 + sentence_list_doc2\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(corpus)\n",
        "doc1vector=vectorizer.transform(sentence_list_doc1)\n",
        "doc2vector=vectorizer.transform(sentence_list_doc2)\n",
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3b43RuXPO47",
        "outputId": "770c7e3a-2190-4725-b461-89844a679c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ability' 'acted' 'actions' 'all' 'alter' 'always' 'amounts' 'and' 'are'\n",
            " 'attributes' 'balance' 'be' 'behavior' 'beings' 'bodies' 'but' 'can'\n",
            " 'cannot' 'consciously' 'decrease' 'decreased' 'encourage' 'external'\n",
            " 'forces' 'from' 'fundamental' 'guna' 'gunas' 'harmony' 'have' 'hindu'\n",
            " 'human' 'humans' 'in' 'increase' 'increased' 'influence' 'interaction'\n",
            " 'karma' 'levels' 'lifestyle' 'minds' 'objects' 'of' 'oneself' 'or' 'our'\n",
            " 'philosophy' 'play' 'practices' 'present' 'purity' 'qualities' 'quality'\n",
            " 'relative' 'removed' 'represents' 'role' 'sattva' 'separated'\n",
            " 'significant' 'surrounding' 'that' 'the' 'their' 'these' 'thoughts'\n",
            " 'three' 'through' 'to' 'unique' 'upon' 'us' 'vary' 'we' 'yoga']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "opAhlRpbynlN",
        "outputId": "fa810b63-d9ef-4aa3-9b99-11ebdf393e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ability'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDd0j5Qsyxrv",
        "outputId": "893e9df8-13ee-4f40-c595-297dcda4f7e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cosine similarity between 2 sentences"
      ],
      "metadata": {
        "id": "0YvM1dfqRDKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cosine similarity between 2 sentences\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "final= cosine_similarity(doc1vector[0],doc2vector[0])"
      ],
      "metadata": {
        "id": "BhiM7wQ0Qf3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#identify max similar sentence\n",
        "max(final.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmAyH5hGQf1I",
        "outputId": "bfc92ee2-27ce-4dc2-c6c0-42b8d7053673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1409898285183983"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1H2oZ1zJ0kUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_list_doc1[0]), print(sentence_list_doc2[0]),"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBEMBagnRe26",
        "outputId": "796b4323-c0e7-4d2c-9761-4ffe7e291c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In Karma Yoga, the three gunas (qualities or attributes) from Hindu  philosophy play a significant role These gunas are fundamental forces that influence human behavior,thoughts,and actions.\n",
            "three gunas are always present in all beings and objects surrounding us but vary in their relative amounts.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#word2vec embeddings"
      ],
      "metadata": {
        "id": "zUx3VCJKSClq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#word2vec ******WORD level embedding creation*****, always keep min_count=1\n",
        "#step1= tokenization, create empty list CORPUS[],\n",
        "#input_test_data= sentence_list_doc1\n",
        "import gensim.models\n",
        "sentence_w2v_list = sentence_list_doc1  #use .tolist() if input is not list as it takes only list as input\n",
        "w2v_corpus=[]\n",
        "for ele in sentence_w2v_list:\n",
        "  w2v_corpus.append(ele.split())\n",
        "\n",
        "model = gensim.models.Word2Vec(sentences=w2v_corpus, min_count=1)"
      ],
      "metadata": {
        "id": "1MohjkQVQfwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Y2C_p_sciPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to see embeeding sof each word model.wv['WORD']\n",
        "print(len(w2v_corpus))\n",
        "print(len(model.wv['Karma']))\n",
        "model.wv['Karma'] #here checked with gunas as input data as word gunas in it"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDjcLZdgQfuV",
        "outputId": "5abd2c6e-11f6-400d-c7ae-1233b2c86c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.30016683e-03, -9.80430283e-03,  4.58776252e-03, -5.38222783e-04,\n",
              "        6.33209571e-03,  1.78347470e-03, -3.12979822e-03,  7.75997294e-03,\n",
              "        1.55466562e-03,  5.52093989e-05, -4.61295387e-03, -8.45352374e-03,\n",
              "       -7.76683213e-03,  8.67050979e-03, -8.92496016e-03,  9.03471559e-03,\n",
              "       -9.28101782e-03, -2.76756298e-04, -1.90704700e-03, -8.93114600e-03,\n",
              "        8.63005966e-03,  6.77781366e-03,  3.01943906e-03,  4.83345287e-03,\n",
              "        1.12190246e-04,  9.42468084e-03,  7.02128746e-03, -9.85372625e-03,\n",
              "       -4.43322072e-03, -1.29011157e-03,  3.04772262e-03, -4.32395237e-03,\n",
              "        1.44916656e-03, -7.84589909e-03,  2.77807354e-03,  4.70269192e-03,\n",
              "        4.93731257e-03, -3.17570218e-03, -8.42704065e-03, -9.22061782e-03,\n",
              "       -7.22899451e-04, -7.32746487e-03, -6.81496272e-03,  6.12000562e-03,\n",
              "        7.17230327e-03,  2.11741915e-03, -7.89940078e-03, -5.69898821e-03,\n",
              "        8.05184525e-03,  3.92084382e-03, -5.24047017e-03, -7.39190448e-03,\n",
              "        7.71554711e-04,  3.46375466e-03,  2.07919348e-03,  3.10080405e-03,\n",
              "       -5.62050007e-03, -9.88948625e-03, -7.02083716e-03,  2.30308768e-04,\n",
              "        4.61867917e-03,  4.52630781e-03,  1.87981245e-03,  5.17067453e-03,\n",
              "       -1.05360748e-04,  4.11416637e-03, -9.12324060e-03,  7.70091172e-03,\n",
              "        6.14747405e-03,  5.12415636e-03,  7.20666908e-03,  8.43979698e-03,\n",
              "        7.38695846e-04, -1.70386070e-03,  5.18628338e-04, -9.31678060e-03,\n",
              "        8.40621442e-03, -6.37993217e-03,  8.42784252e-03, -4.24435502e-03,\n",
              "        6.46842702e-04, -9.16416850e-03, -9.55856778e-03, -7.83681031e-03,\n",
              "       -7.73105631e-03,  3.75581993e-04, -7.22646248e-03, -4.95021325e-03,\n",
              "       -5.27170673e-03, -4.28929785e-03,  7.01231137e-03,  4.82938997e-03,\n",
              "        8.68277065e-03,  7.09359162e-03, -5.69440611e-03,  7.24079600e-03,\n",
              "       -9.29490291e-03, -2.58756871e-03, -7.75716640e-03,  4.19260142e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate word vectors using Word2Vec"
      ],
      "metadata": {
        "id": "Ma2UzyaQWAQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Python program to generate word vectors using Word2Vec\n",
        "#https://www.geeksforgeeks.org/python-word-embedding-using-word2vec/\n",
        "\n",
        "# importing all necessary modules\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action = 'ignore')\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# # Reads ‘alice.txt’ file\n",
        "# sample = open(\"C:\\\\Users\\\\Admin\\\\Desktop\\\\alice.txt\", \"utf8\")\n",
        "# s = sample.read()\n",
        "# # Replaces escape character with space\n",
        "# f = s.replace(\"\\n\", \" \")\n",
        "# data = []\n",
        "# # iterate through each sentence in the file\n",
        "# for i in sent_tokenize(f):\n",
        "# \ttemp = []\n",
        "# \t# tokenize the sentence into words\n",
        "# \tfor j in word_tokenize(i):\n",
        "# \t\ttemp.append(j.lower())\n",
        "# \tdata.append(temp)\n",
        "\n",
        "# Create CBOW model -CBOW (Continuous Bag of Words): CBOW model predicts the current word given\n",
        "                                                     #context words within a specific window.\n",
        "model1 = gensim.models.Word2Vec(w2v_corpus, min_count = 1,\n",
        "\t\t\t\t\t\t\tvector_size = 100, window = 5)\n",
        "\n",
        "# Print results\n",
        "print(\"Cosine similarity between 'play' \" +\n",
        "\t\t\t\"and 'role' - CBOW : \",\n",
        "\tmodel1.wv.similarity('play', 'role'))\n",
        "\n",
        "print(\"Cosine similarity between 'gunas' \" +\n",
        "\t\t\t\t\"and 'play' - CBOW : \",\n",
        "\tmodel1.wv.similarity('gunas', 'play'))\n",
        "\n",
        "# Create Skip Gram model - Skip Gram : Skip gram predicts the surrounding context words\n",
        "model2 = gensim.models.Word2Vec(w2v_corpus, min_count = 1, vector_size = 100,\n",
        "\t\t\t\t\t\t\t\t\t\t\twindow = 5, sg = 1)\n",
        "\n",
        "# Print results\n",
        "print(\"Cosine similarity between 'play' \" +\n",
        "\t\t\t\"and 'role' - Skip Gram : \",\n",
        "\tmodel2.wv.similarity('play', 'role'))\n",
        "\n",
        "print(\"Cosine similarity between 'gunas' \" +\n",
        "\t\t\t\t\"and 'play' - Skip Gram : \",\n",
        "\tmodel2.wv.similarity('gunas', 'play'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXRuXRWIY4Uh",
        "outputId": "070367ac-0853-4abc-9e8a-cf80ce222edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'play' and 'role' - CBOW :  0.060591854\n",
            "Cosine similarity between 'gunas' and 'play' - CBOW :  0.026789693\n",
            "Cosine similarity between 'play' and 'role' - Skip Gram :  0.060591854\n",
            "Cosine similarity between 'gunas' and 'play' - Skip Gram :  0.026156237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#bag of words"
      ],
      "metadata": {
        "id": "3e_HbgoUyUxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4ikiV3T8yUni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bag of words word embeeding = vectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = sentence_list_doc1 + sentence_list_doc2\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(corpus)\n",
        "doc1vector=vectorizer.transform(sentence_list_doc1)\n",
        "doc2vector=vectorizer.transform(sentence_list_doc2)\n",
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yre5aNi1yP_0",
        "outputId": "e0977473-4d28-4063-b88e-d9fb8b07c074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ability' 'acted' 'actions' 'all' 'alter' 'always' 'amounts' 'and' 'are'\n",
            " 'attributes' 'balance' 'be' 'behavior' 'beings' 'bodies' 'but' 'can'\n",
            " 'cannot' 'consciously' 'decrease' 'decreased' 'encourage' 'external'\n",
            " 'forces' 'from' 'fundamental' 'guna' 'gunas' 'harmony' 'have' 'hindu'\n",
            " 'human' 'humans' 'in' 'increase' 'increased' 'influence' 'interaction'\n",
            " 'karma' 'levels' 'lifestyle' 'minds' 'objects' 'of' 'oneself' 'or' 'our'\n",
            " 'philosophy' 'play' 'practices' 'present' 'purity' 'qualities' 'quality'\n",
            " 'relative' 'removed' 'represents' 'role' 'sattva' 'separated'\n",
            " 'significant' 'surrounding' 'that' 'the' 'their' 'these' 'thoughts'\n",
            " 'three' 'through' 'to' 'unique' 'upon' 'us' 'vary' 'we' 'yoga']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "wd951GLdY4Qm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c9d8c3c-0c87-4ca6-85ba-b88abffdee86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cosine similarity between 2 sentences\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "final= cosine_similarity(doc1vector[0],doc2vector[0])"
      ],
      "metadata": {
        "id": "KgQV_7SaY4Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#identify max similar sentence\n",
        "max(final.ravel())"
      ],
      "metadata": {
        "id": "ux1IZ9MIY4Ft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad54ea84-21b3-4275-9a84-09ea270fea22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2906591794880899"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# class tokensizer - NLP data prep"
      ],
      "metadata": {
        "id": "Azj82GYq_eLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #x= train_df[\"sentence\"]\n",
        "# Libraries and packages for text (pre-)processing\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# For type hinting\n",
        "from typing import List"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqEXTpDp_-G5",
        "outputId": "da17b97a-87b4-45a3-a791-f0be3f522c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer:\n",
        "    \"\"\" After cleaning and denoising steps, in this class the text is broken up into tokens.\n",
        "    if clean: clean the text from all non-alphanumeric characters,\n",
        "    if lower: convert the text into lowercase,\n",
        "    If de_noise: remove HTML and URL components,\n",
        "    if remove_stop_words: and remove stop-words,\n",
        "    If keep_neagation: attach the negation tokens to the next token\n",
        "     and treat them as a single word before removing the stopwords\n",
        "\n",
        "    Returns:\n",
        "    List of tokens\n",
        "    \"\"\"\n",
        "    # initialization method to create the default instance constructor for the class\n",
        "    def __init__(self,\n",
        "                 clean: bool = True,\n",
        "                 lower: bool = True,\n",
        "                 de_noise: bool = True,\n",
        "                 remove_stop_words: bool = True,\n",
        "                keep_negation: bool = True) -> List[str]:\n",
        "\n",
        "        self.de_noise = de_noise\n",
        "        self.remove_stop_words = remove_stop_words\n",
        "        self.clean = clean\n",
        "        self.lower = lower\n",
        "        self.stopwords = nltk.corpus.stopwords.words('english')\n",
        "        self.keep_negation = keep_negation\n",
        "\n",
        "    # other methods\n",
        "    def denoise(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        Removing html and URL components\n",
        "        \"\"\"\n",
        "        html_pattern = r\"<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});\"\n",
        "        url_pattern = r\"((http://)[^ ]*|(https://)[^ ]*|(www\\.)[^ ]*)\"\n",
        "\n",
        "        text = re.sub(html_pattern, \" \", text)\n",
        "        text = re.sub(url_pattern,\" \",text).strip()\n",
        "        return text\n",
        "\n",
        "\n",
        "    def remove_stopwords(self, tokenized_text: List[str]) -> List[str]:\n",
        "        text = [word for word in tokenized_text if word not in self.stopwords]\n",
        "        return text\n",
        "\n",
        "\n",
        "    def keep_negation_sw(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        A function to save negation words (n't, not, no) from removing as stopwords\n",
        "        \"\"\"\n",
        "        # to replace \"n't\" with \"not\"\n",
        "        text = re.sub(r\"won\\'t\", \"will not\", text)\n",
        "        text = re.sub(r\"can\\'t\", \"can not\", text)\n",
        "        text = re.sub(r\"n\\'t\", \" not\", text)\n",
        "        # to join not/no into the next word\n",
        "        text = re.sub(\"not \", \" NOT\", text)\n",
        "        text = re.sub(\"no \", \" NO\", text)\n",
        "        return text\n",
        "\n",
        "\n",
        "    def tokenize(self, text: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        A function to tokenize words of the text\n",
        "        \"\"\"\n",
        "        non_alphanumeric_pattern =r\"[^a-zA-Z0-9]\"\n",
        "\n",
        "        # to substitute multiple whitespace with single whitespace\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        if self.de_noise:\n",
        "            text = self.denoise(text)\n",
        "        if self.lower:\n",
        "            text = text.lower()\n",
        "        if self.keep_negation:\n",
        "            text = self.keep_negation_sw(text)\n",
        "\n",
        "        if self.clean:\n",
        "            # to remove non-alphanumeric characters\n",
        "            text = re.sub(non_alphanumeric_pattern,\" \", text).strip()\n",
        "\n",
        "        tokenized_text = text.split()\n",
        "\n",
        "        if self.remove_stop_words:\n",
        "            tokenized_text = self.remove_stopwords(tokenized_text)\n",
        "\n",
        "        return tokenized_text\n"
      ],
      "metadata": {
        "id": "M15iUkgM2Bhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "use tokenizer"
      ],
      "metadata": {
        "id": "jSLyz2iV_t5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list_doc1= np.asarray(sentence_list_doc1)"
      ],
      "metadata": {
        "id": "TFyY8JQvAKom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data()x= train_df[\"sentence\"]\n",
        "# Instancing the Tokenizer class\n",
        "tokenizer = Tokenizer(clean= True,\n",
        "                      lower= True,\n",
        "                      de_noise= True,\n",
        "                      remove_stop_words= True,\n",
        "                      keep_negation=True)\n",
        "\n",
        "#print(tokenizer.tokenize(train_df[\"sentence\"].iloc[0])) #pass your data (x) here instread of \"train_df[\"sentence]\"\n",
        "\n",
        "token_list=[]\n",
        "for ele in sentence_list_doc1.tolist(): #pass your document name here \"sentence_list_doc1\"\n",
        "  token_list.append(tokenizer.tokenize(ele))\n",
        "token_list\n",
        "len(token_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mb6Oqj7AECS",
        "outputId": "ba9d6b6c-ba50-4ada-cb2a-5fdcab12eddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(token_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1g958d4Am4C",
        "outputId": "0f4dcb59-6ac5-4aff-8d18-b7f011a98a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['karma', 'yoga', 'three', 'gunas', 'qualities', 'attributes', 'hindu', 'philosophy', 'play', 'significant', 'role', 'gunas', 'fundamental', 'forces', 'influence', 'human', 'behavior', 'thoughts', 'actions'], ['three', 'gunas', 'sattva', 'purity', 'harmony', 'sattva', 'represents', 'quality', 'purity', 'harmony', 'balance']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data1= pd.Series(test_data1)\n",
        "type(test_data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9j25xqW2Gle",
        "outputId": "fe241dfa-ec34-4f46-de7f-cc0b0dfcfe34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data1_processed=test_data1.apply(preprocess)\n",
        "test_data1_processed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNZkV8v91l3R",
        "outputId": "bdc0c034-2817-4a27-bd0a-ce4bac7caabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    in karma yoga  the three gunas  qualities or a...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data1_processed[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "EA50ypd9HyKs",
        "outputId": "769fc018-37c3-4aa3-e326-7a59a1f49359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'in karma yoga  the three gunas  qualities or attributes  from hindu  philosophy play a significant role these gunas are fundamental forces that influence human behavior thoughts and actions  the three gunas are sattva   purity  harmony    sattva represents the quality of purity harmony  and balance '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B44bs5NzKoLw",
        "outputId": "18976006-69f6-42b6-c5b8-2c551627dc64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    three gunas are always present in all beings a...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is3B8IX-K4pX",
        "outputId": "3efeef5b-d562-43f7-e844-9761ea52c350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ]
}